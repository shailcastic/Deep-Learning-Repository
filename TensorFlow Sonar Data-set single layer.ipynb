{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single layer perceptron example class3 code example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\SHAILESH TIWARI\\\\New_Datasets\\\\DL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for data processing and dataframe\n",
    "import numpy as np #for numerical and matrix multiplication\n",
    "import matplotlib.pyplot as plt  #graph visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import  shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('sonar_data.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using single perceptron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the function for task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to read the sonar dataset\n",
    "def read_dataset():\n",
    "    df = pd.read_csv(\"sonar_data.csv\",header=None)\n",
    "    print(len(df.columns))\n",
    "    X = df[df.columns[1:60]].values\n",
    "    y=df[df.columns[60]]\n",
    "    #encode the depedent variable, single it has more than one class\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    y = encoder.transform(y)\n",
    "    Y = one_hot_encode(y)\n",
    "    return(X,Y,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalise the features of the dataset\n",
    "def feature_normalize(features):\n",
    "    mu = np.mean(features,axis=0)\n",
    "    sigma = np.std(features,axis=0)\n",
    "    normalize_features = (features - mu) / sigma\n",
    "    return(normalize_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#appending the bias\n",
    "def append_bias_reshape(features):\n",
    "    n_training_samples = features.shape[0]\n",
    "    n_dim = features.shape[1]\n",
    "    features = np.reshape(np.c_[np.ones(n_training_samples),features],[n_training_samples,n_dim+1])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#define the one hot encode function\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the graph for the data\n",
    "def plot_points(features,labels):\n",
    "    normal = np.where(labels == 0)\n",
    "    outliers = np.where(labels == 1)\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    plt.plot(features[normal ,0],features[normal ,1],'bx')\n",
    "    plt.plot(features[outliers,0],features[outliers ,1],'ro')\n",
    "    plt.xlabel('Latency (ms)')\n",
    "    plt.ylabel('Throughput (mb/s)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data\n",
    "X,Y,y = read_dataset() #X - Features , Y - Labels\n",
    "normalized_featues = feature_normalize(X)\n",
    "plot_points(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the data in training and testing\n",
    "X,Y = shuffle(X,Y,random_state=1)\n",
    "train_x,test_x,train_y,test_y = train_test_split(X,Y,test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print the shape of the train and test data values\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define and initialize the variables to work with the tensors\n",
    "learning_rate = 0.1\n",
    "training_epochs = 1000\n",
    "\n",
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "\n",
    "n_dim = X.shape[1]\n",
    "n_class = 2\n",
    "\n",
    "x = tf.placeholder(tf.float32,[None,n_dim])\n",
    "W = tf.Variable(tf.zeros([n_dim,n_class]))\n",
    "b = tf.Variable(tf.zeros([n_class]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize all variables.\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the cost function\n",
    "y_ = tf.placeholder(tf.float32,[None,n_class])\n",
    "y = tf.nn.softmax(tf.matmul(x, W)+ b)\n",
    "cost_function = tf.reduce_mean(-tf.reduce_sum((y_ * tf.log(y)),reduction_indices=[1]))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the session\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "mse_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the cost for each epoch\n",
    "for epoch in range(training_epochs):\n",
    "    sess.run(training_step,feed_dict={x:train_x,y_:train_y})\n",
    "    cost = sess.run(cost_function,feed_dict={x: train_x,y_: train_y})\n",
    "    cost_history = np.append(cost_history,cost)\n",
    "    pred_y = sess.run(y, feed_dict={x: test_x})\n",
    "    print('epoch : ', epoch,  ' - ', 'cost: ', cost)\n",
    "\n",
    "\n",
    "    mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "    mse_history.append(sess.run(mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the final mean square error\n",
    "print(\"MSE:\",mse_history)\n",
    "plt.plot(mse_history, 'ro-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Accuracy: \",(sess.run(accuracy, feed_dict={x: test_x, y_: test_y})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.argmax(y,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In[15]:\n",
    "\n",
    "plt.plot(range(len(cost_history)),cost_history)\n",
    "plt.axis([0,training_epochs,0,np.max(cost_history)])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[16]:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
